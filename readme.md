# Customer Churn Prediction Pipeline

This project builds a **Customer Churn Prediction Pipeline** using the [Telco Customer Churn Dataset](https://www.kaggle.com/datasets/blastchar/telco-customer-churn).  
It demonstrates how to design a full machine learning workflow: **ingestion â†’ preprocessing â†’ training â†’ prediction â†’ storage â†’ orchestration**.

---

## Project Structure

customer_churn_pipeline/
â”‚â”€â”€ data/
â”‚ â”œâ”€â”€ raw/ # original churn.csv dataset
â”‚ â””â”€â”€ processed/ # cleaned dataset (churn_clean.csv)
â”‚â”€â”€ models/ # trained model + preprocessing pipeline
â”‚â”€â”€ notebooks/ # Jupyter notebooks for EDA
â”‚â”€â”€ src/ # source code
â”‚ â”œâ”€â”€ ingest.py # ingest raw data
â”‚ â”œâ”€â”€ transform.py # preprocess data (encode, scale, clean)
â”‚ â”œâ”€â”€ train.py # train ML models
â”‚ â”œâ”€â”€ predict.py # generate predictions & save to DB
â”‚ â”œâ”€â”€ query_predictions.py # check stored predictions
â”‚ â””â”€â”€ flow.py # orchestrate full pipeline (Prefect)
â”‚â”€â”€ db/ # SQLite database (churn.db)
â”‚â”€â”€ requirements.txt # dependencies
â”‚â”€â”€ README.md # project documentation
â”‚â”€â”€ .gitignore # files ignored by Git

---

## ğŸš€ How It Works

1. **Ingest Data**

   - Load raw `churn.csv` into `data/raw/`.

2. **Transform Data**

   - Drop unused columns (`customerID`).
   - Convert `TotalCharges` â†’ numeric.
   - Encode categorical features.
   - Scale numerical features.
   - Save clean dataset â†’ `data/processed/churn_clean.csv`.
   - Save preprocessor â†’ `models/preprocessor.pkl`.

3. **Train Model**

   - Train Logistic Regression, RandomForest, and XGBoost.
   - Compare metrics (Accuracy, F1, AUC).
   - Save best model â†’ `models/churn_model.pkl`.

4. **Predict**

   - Load saved model + preprocessor.
   - Score new customer data (`data/raw/new_customers.csv`).
   - Save predictions to SQLite (`db/churn.db`, table: `churn_predictions`).

5. **Query Predictions**

   - Fetch stored predictions from database for analysis.

6. **Orchestrate**
   - Prefect flow (`flow.py`) automates the entire pipeline:
     ```
     ingest â†’ transform â†’ train â†’ predict
     ```

---

## âš™ï¸ Installation

````bash
git clone <your-repo-url>
cd customer_churn_pipeline

# Create virtual environment
python -m venv venv
source venv/bin/activate    # Mac/Linux
venv\Scripts\activate       # Windows

# Install dependencies
pip install -r requirements.txt



## â–¶ï¸ Usage

### Run full pipeline
```bash
python src/flow.py
python src/ingest.py
python src/transform.py
python src/train.py
python src/predict.py
python src/query_predictions.py

## ğŸ“Š Dataset

- **Name:** Telco Customer Churn Dataset
- **Records:** 7,043 customers
- **Features:** 21
- **Target:** `Churn (Yes/No)`

---

## ğŸ“Œ Features

- End-to-end modular ML pipeline
- Multiple models: Logistic Regression, RandomForest, XGBoost
- SQLite storage for predictions
- Prefect orchestration for automation
- Easy to extend to PostgreSQL or API deployment

---


````
